#============================================================================================
#Basic Settings
#============================================================================================
setwd("Downloads/Econ 613/A4/Data/")
setwd("D:/ECON 613/A4/Data/")
options(scipen = 200)
#============================================================================================
#Import Packages
#============================================================================================
library(margins)
library(readr)
library(tidyverse)
library(data.table)
library(dplyr)
library(mlogit)
library(nnet)
library(esquisse)
library(survival)
library(AER)
#============================================================================================
#Import Datasets
dat_a4 <- read_csv("dat_A4.csv")
dat_a4_panel <- read_csv("dat_A4_panel.csv")
#============================================================================================
#Exercise 1 
#============================================================================================
#Create Variables
#============================================================================================
dat_a4$age <- 2019 - dat_a4$KEY_BDATE_Y_1997 - 1
dat_a4$work_exp <- rowSums(dat_a4[,18:28],na.rm = 'TRUE')/48

c1 <- which(dat_a4$CV_HGC_BIO_DAD_1997==95)
c2 <- which(dat_a4$CV_HGC_BIO_MOM_1997==95)
c3 <- which(dat_a4$CV_HGC_RES_DAD_1997==95)
c4 <- which(dat_a4$CV_HGC_BIO_MOM_1997==95)
dat_a4$CV_HGC_BIO_DAD_1997[c1] <- NA
dat_a4$CV_HGC_BIO_MOM_1997[c2] <- NA
dat_a4$CV_HGC_RES_DAD_1997[c3] <- NA
dat_a4$CV_HGC_BIO_MOM_1997[c4] <- NA

dat_a4$edu_bio <- rowSums(dat_a4[,8:9],na.rm = 'TRUE')
dat_a4$edu_res <- rowSums(dat_a4[,10:11],na.rm = 'TRUE')
#============================================================================================
#Visualization 1.3.1
dat_a4$age <- as.factor(dat_a4$age)
dat_a4$KEY_SEX_1997 <- as.factor(dat_a4$KEY_SEX_1997)
dat_a4$CV_BIO_CHILD_HH_U18_2019 <- as.factor(dat_a4$CV_BIO_CHILD_HH_U18_2019)
dat_a4[,30][is.na(dat_a4[,30])] <- 0
dat_a4_ig0 <- subset(dat_a4,dat_a4$YINC_1700_2019 > 0)
income_age <- dat_a4_ig0 %>% group_by(age) %>% summarise(income = mean(YINC_1700_2019))
income_gender <- dat_a4_ig0 %>% group_by(KEY_SEX_1997) %>% summarise(income = mean(YINC_1700_2019))
dat_a4_male <- subset(dat_a4,KEY_SEX_1997==1)
dat_a4_female <- subset(dat_a4,KEY_SEX_1997==2)
income_child <- dat_a4_ig0 %>% group_by(CV_BIO_CHILD_HH_U18_2019) %>% summarise(income = mean(YINC_1700_2019))
ggplot(income_age) +
  aes(x = age, weight = income) +
  geom_bar(fill = "#112446") +
  labs(
    y = "average income",
    title = "Average Income with Age"
  ) +
  theme_light() +
  theme(plot.title = element_text(size = 15L, hjust = 0.5))
hist(dat_a4_male$YINC_1700_2019)
hist(dat_a4_female$YINC_1700_2019)
ggplot(income_gender) +
  aes(x = KEY_SEX_1997, fill = KEY_SEX_1997, weight = income) +
  geom_bar() +
  scale_fill_manual(
    values = c(`1` = "#F8766D",
               `2` = "#FF61C3")
  ) +
  labs(
    y = "average income",
    title = "Average Income with Gender"
  ) +
  theme_light() +
  theme(plot.title = element_text(size = 15L))
ggplot(income_child) +
  aes(
    x = CV_BIO_CHILD_HH_U18_2019,
    fill = CV_BIO_CHILD_HH_U18_2019,
    weight = income
  ) +
  geom_bar() +
  scale_fill_hue(direction = 1) +
  labs(
    x = "number of children",
    y = "average income",
    title = "Average Income with Number of Children"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(size = 15L, hjust = 0.5))
#============================================================================================
#Visualization 1.3.2
#============================================================================================
s0_age <- dat_a4 %>% group_by(age) %>% summarize(s0=length(which((YINC_1700_2019==0)=='TRUE'))/length(YINC_1700_2019)) 
s0_gender <- dat_a4 %>% group_by(KEY_SEX_1997) %>% summarize(s0=length(which((YINC_1700_2019==0)=='TRUE'))/length(YINC_1700_2019)) 
s0_child_marital <- dat_a4 %>% group_by(CV_BIO_CHILD_HH_U18_2019,CV_MARSTAT_COLLAPSED_2019) %>% summarize(s0=length(which((YINC_1700_2019==0)=='TRUE'))/length(YINC_1700_2019))  
s0_child_marital <- subset(s0_child_marital,CV_BIO_CHILD_HH_U18_2019!='NA'&CV_MARSTAT_COLLAPSED_2019!='NA')
s0_child_marital$status <- paste(s0_child_marital$CV_BIO_CHILD_HH_U18_2019,s0_child_marital$CV_MARSTAT_COLLAPSED_2019,sep = ',')
ggplot(s0_age) 
  aes(x = age, fill = age, weight = s0) +
  geom_bar() +
  scale_fill_hue(direction = 1) +
  theme_minimal()
  
ggplot(s0_child_marital) +
  aes(x = status, fill = status, weight = s0) +
  geom_bar() +
  scale_fill_hue(direction = 1) +
  theme_minimal()
  
ggplot(s0_gender) +
  aes(x = KEY_SEX_1997, fill = KEY_SEX_1997, weight = s0) +
  geom_bar() +
  scale_fill_hue(direction = 1) +
  labs(y = "share of 0") +
  theme_minimal()
#============================================================================================
#Exercise 2
#============================================================================================
#Prepare Data
#============================================================================================
dat_a4$d1 <- 0
dat_a4$d1[which(dat_a4$YINC_1700_2019>0)] <- 1
dat_a4$inter <- 1

x1 = dat_a4$inter
x2 = dat_a4$KEY_SEX_1997
x3 = dat_a4$age
x4 = dat_a4$work_exp
x5 = dat_a4$edu_bio
y  = dat_a4$YINC_1700_2019
d1 = dat_a4$d1
#============================================================================================
#OLS, Includes variables: age/gender/exper/edu_bio
#============================================================================================
ols_1 <- lm(y~x2+x3+x4+x5)
summary(ols_1)
#Heckman Selection Model
#============================================================================================
#Step 1: Probit Estimation of Probability
reg1 <- glm(d1~x2+x3+x4+x5,family = binomial(link = "probit"))
summary(reg1)
 
start <- runif(5,-1,1)
probit_flike = function(par,x1,x2,x3,x4,x5,d1){
  yhat = par[1]*x1 + par[2]*x2 + par[3]*x3 + par[4]*x4 + par[5]*x5 
  prob = pnorm(yhat)
  like = d1*log(prob) + (1-d1)*log(1-prob)
  return(-sum(like))
}
res  <- optim(noise_1,fn=probit_flike,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),x1=x1,x2=x2,x3=x3,x4=x4,x5=x5,d1=d1,hessian=TRUE)
res$par
#Inverse Mills Ratio
predictor_fun = function(par,x1,x2,x3,x4,x5,d1){
  yhat = par[1]*x1 + par[2]*x2 + par[3]*x3 + par[4]*x4 + par[5]*x5
  return(yhat)
}
predictor <- predictor_fun(res$par,x1,x2,x3,x4,x5,d1)
imr <- dnorm(predictor)/pnorm(predictor)
#Step 2: Include Inverse Mills Ratio as a Regressor
ols_heckman <- lm(y~x2+x3+x4+x5+imr)
summary(ols_heckman)
#============================================================================================
#Exercise 3
#============================================================================================
ggplot(dat_a4_ig0) +
  aes(x = YINC_1700_2019) +
  geom_histogram(bins = 30L, fill = "#4682B4") +
  labs(
    x = "income",
    y = "density",
    title = "Histogram of Income"
  ) +
  theme_light()
#============================================================================================
#Use Tobit Model: Include still variables: age/gender/exper/edu_bio
#============================================================================================
dat_a4$d2 <- 0
dat_a4$d2[which(dat_a4$YINC_1700_2019<100000)] <- 1
d2 <- dat_a4$d2

reg_tobit <- tobit(y ~ x2 + x3 + x4 + x5,right = 100000)
summary(reg_tobit)
tobit_flike = function(par,x1,x2,x3,x4,x5,d2,y){
  yhat = par[1]*x1 + par[2]*x2 + par[3]*x3 + par[4]*x4 + par[5]*x5 
  residual = y - yhat
  like = d2*log(dnorm(residual)) + (1-d2)*log(1 - pnorm(-yhat))
  return(-sum(like))
}

tobit_flike(reg_tobit$coefficients,x1,x2,x3,x4,x5,d2,y)
start_2 <- runif(5,-0.5,0.5)
res_2 <- optim(reg_tobit$coefficients,fn=tobit_flike,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),x1=x1,x2=x2,x3=x3,x4=x4,x5=x5,d2=d2,y=y,hessian=TRUE)

view(tobit)


#Exercise 4
dat_a4_panel <- read_csv("dat_A4_panel.csv")
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_1998=CV_HIGHEST_DEGREE_9899_1998)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_1999=CV_HIGHEST_DEGREE_9900_1999)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2000=CV_HIGHEST_DEGREE_0001_2000)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2001=CV_HIGHEST_DEGREE_0102_2001)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2002=CV_HIGHEST_DEGREE_0203_2002)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2003=CV_HIGHEST_DEGREE_0304_2003)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2004=CV_HIGHEST_DEGREE_0405_2004)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2005=CV_HIGHEST_DEGREE_0506_2005)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2006=CV_HIGHEST_DEGREE_0607_2006)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2007=CV_HIGHEST_DEGREE_0708_2007)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2008=CV_HIGHEST_DEGREE_0809_2008)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2009=CV_HIGHEST_DEGREE_0910_2009)
dat_a4_panel <- dat_a4_panel %>% rename(CV_HIGHEST_DEGREE_EVER_EDT_2010=CV_HIGHEST_DEGREE_1011_2010)

dat_a4_panel_long <- long_panel(dat_a4_panel,prefix='_',begin  = 1997, end = 2019,label_location = "end")
dat_a4_panel_long <- subset(dat_a4_panel_long,wave!='2012' & wave!='2014' & wave!='2016' & wave!='2018')
dat_a4_panel_long <- select(dat_a4_panel_long,c(1:18,22:30))



a<-dat_a4_panel_long[,c(10:16,20:27)]
a[is.na(a[3:17])]<-0
a$work_exp <- rowSums(a[,3:17])/48









